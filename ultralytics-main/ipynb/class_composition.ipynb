{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label과 Class 정보 뽑아서 백업 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 0번 label과 class만 뽑아 오기 #####\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_directories_and_clean(labels_dir, images_dir, new_labels_dir, new_images_dir):\n",
    "    os.makedirs(new_labels_dir, exist_ok=True)\n",
    "    os.makedirs(new_images_dir, exist_ok=True)\n",
    "\n",
    "    # 기존 디렉토리의 모든 파일을 새로운 디렉토리로 복사\n",
    "    for label_file in os.listdir(labels_dir):\n",
    "        if label_file.endswith('.txt'):\n",
    "            # 라벨 파일 복사\n",
    "            old_label_path = os.path.join(labels_dir, label_file)\n",
    "            new_label_path = os.path.join(new_labels_dir, label_file)\n",
    "            shutil.copy2(old_label_path, new_label_path)\n",
    "\n",
    "            # 대응하는 이미지 파일 복사\n",
    "            image_file = label_file.replace('.txt', '.jpg')\n",
    "            old_image_path = os.path.join(images_dir, image_file)\n",
    "            new_image_path = os.path.join(new_images_dir, image_file)\n",
    "            \n",
    "            if os.path.exists(old_image_path):\n",
    "                shutil.copy2(old_image_path, new_image_path)\n",
    "\n",
    "    # 복사된 파일들을 대상으로 클래스 0만 남기고 나머지 삭제\n",
    "    for label_file in os.listdir(new_labels_dir):\n",
    "        if label_file.endswith('.txt'):\n",
    "            label_path = os.path.join(new_labels_dir, label_file)\n",
    "            \n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # 클래스 0인 라인만 남기기\n",
    "            class_0_lines = [line for line in lines if line.strip().split()[0] == '0']\n",
    "\n",
    "            if class_0_lines:\n",
    "                # 클래스 0이 있는 경우: 라벨 파일을 덮어쓰기\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.writelines(class_0_lines)\n",
    "            else:\n",
    "                # 클래스 0이 없는 경우, 해당 라벨과 이미지 파일 삭제\n",
    "                os.remove(label_path)\n",
    "                image_file = label_file.replace('.txt', '.jpg')\n",
    "                image_path = os.path.join(new_images_dir, image_file)\n",
    "                if os.path.exists(image_path):\n",
    "                    os.remove(image_path)\n",
    "\n",
    "# 기존 디렉토리 경로\n",
    "train_labels_dir = 'ultralytics_dataset/train/labels'\n",
    "train_images_dir = 'ultralytics_dataset/train/images'\n",
    "new_train_labels_dir = 'ultralytics_clustering/train/labels_class_0'\n",
    "new_train_images_dir = 'ultralytics_clustering/train/images_class_0'\n",
    "\n",
    "val_labels_dir = 'ultralytics_dataset/val/labels'\n",
    "val_images_dir = 'ultralytics_dataset/val/images'\n",
    "new_val_labels_dir = 'ultralytics_clustering/val/labels_class_0'\n",
    "new_val_images_dir = 'ultralytics_clustering/val/images_class_0'\n",
    "\n",
    "# 클래스 0만 추출하여 새로운 디렉토리에서 정제 (train set)\n",
    "copy_directories_and_clean(train_labels_dir, train_images_dir, new_train_labels_dir, new_train_images_dir)\n",
    "\n",
    "# 클래스 0만 추출하여 새로운 디렉토리에서 정제 (validation set)\n",
    "copy_directories_and_clean(val_labels_dir, val_images_dir, new_val_labels_dir, new_val_images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPN 출력 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from ultralytics import RTDETR\n",
    "\n",
    "model = RTDETR('rtdetr-l.pt')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 후크를 사용하여 FPN 출력 추출\n",
    "fpn_features = []\n",
    "\n",
    "# 후크를 등록할 함수 (FPN 레이어의 출력을 추출)\n",
    "def get_fpn_features(module, input, output):\n",
    "    fpn_features.append(output)\n",
    "\n",
    "# FPN 관련된 RepC3 레이어들에 후크 등록\n",
    "fpn_layer_indices = [16, 21, 24, 27]  # FPN에 해당하는 레이어들로 추정\n",
    "for idx in fpn_layer_indices:\n",
    "    module = model.model.model[idx]\n",
    "    print(f\"Registering hook on RepC3 at layer {idx}\")\n",
    "    module.register_forward_hook(get_fpn_features)\n",
    "    \n",
    "# 이미지 전처리 함수\n",
    "def preprocess_image(image_path, input_size=1024):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img = transform(img).unsqueeze(0)  # 배치 차원 추가\n",
    "    img = torch.clamp(img, 0.0, 1.0)\n",
    "\n",
    "    return img\n",
    "    \n",
    "# 라벨 파일에서 바운딩 박스 정보 읽기 (YOLO 형식 -> 픽셀 좌표 변환)\n",
    "def read_bboxes(label_path, img_width, img_height):\n",
    "    bboxes = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            if class_id == 0:  # general trash (클래스 번호 0번)\n",
    "                # YOLO 형식 (x_center, y_center, width, height)을 픽셀 좌표로 변환\n",
    "                x_center, y_center, width, height = map(float, parts[1:])\n",
    "                x_center *= img_width\n",
    "                y_center *= img_height\n",
    "                width *= img_width\n",
    "                height *= img_height\n",
    "                x_min = int(x_center - width / 2)\n",
    "                y_min = int(y_center - height / 2)\n",
    "                x_max = int(x_center + width / 2)\n",
    "                y_max = int(y_center + height / 2)\n",
    "                bboxes.append([x_min, y_min, x_max, y_max])\n",
    "    return bboxes\n",
    "\n",
    "# 바운딩 박스 좌표를 feature map 크기에 맞게 스케일링\n",
    "def scale_bboxes(bboxes, img_size, feature_map_size):\n",
    "    img_width, img_height = img_size\n",
    "    fpn_width, fpn_height = feature_map_size\n",
    "\n",
    "    scaled_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        x_min = int(x_min * fpn_width / img_width)\n",
    "        y_min = int(y_min * fpn_height / img_height)\n",
    "        x_max = int(x_max * fpn_width / img_width)\n",
    "        y_max = int(y_max * fpn_height / img_height)\n",
    "        scaled_bboxes.append([x_min, y_min, x_max, y_max])\n",
    "    \n",
    "    return scaled_bboxes\n",
    "\n",
    "def extract_features(image_path, label_path):\n",
    "    img = preprocess_image(image_path)\n",
    "    img = img.to(model.device)  # 모델 장치로 이미지 이동\n",
    "    \n",
    "    # 원본 이미지 크기 (전처리된 이미지 크기가 아님)\n",
    "    original_img = Image.open(image_path)\n",
    "    img_width, img_height = original_img.size\n",
    "    \n",
    "    # 라벨 파일에서 바운딩 박스 정보 추출\n",
    "    bboxes = read_bboxes(label_path, img_width, img_height)\n",
    "    print(f\"Found {len(bboxes)} bounding boxes in {image_path}\")\n",
    "    # 모델 추론을 수행하여 후크에서 FPN 출력 추출\n",
    "    model(img)\n",
    "    \n",
    "    # FPN 출력 결합\n",
    "    if fpn_features:  # 4개의 FPN 출력이 저장되어 있음\n",
    "        print(f\"Extracting features from {len(fpn_features)} FPN outputs\")\n",
    "        bbox_features = []\n",
    "        \n",
    "        for fpn_output in fpn_features:\n",
    "            # FPN 피쳐맵 크기\n",
    "            fpn_height, fpn_width = fpn_output.shape[2], fpn_output.shape[3]\n",
    "            \n",
    "            # 바운딩 박스 좌표를 feature map 크기에 맞게 변환\n",
    "            scaled_bboxes = scale_bboxes(bboxes, (img_width, img_height), (fpn_width, fpn_height))\n",
    "            \n",
    "            # 바운딩 박스 내의 특징을 추출하여 결합\n",
    "            for bbox in scaled_bboxes:\n",
    "                x_min, y_min, x_max, y_max = bbox\n",
    "                # 바운딩 박스 영역의 피쳐맵을 추출\n",
    "                bbox_feature = fpn_output[:, :, y_min:y_max, x_min:x_max]\n",
    "                # Global Average Pooling\n",
    "                pooled_feature = torch.mean(bbox_feature, dim=[2, 3])  # (N, C)\n",
    "                bbox_features.append(pooled_feature)\n",
    "\n",
    "        fpn_features.clear()  # 다음 이미지를 위해 초기화\n",
    "\n",
    "        if bbox_features:\n",
    "            # 바운딩 박스별로 추출된 특징을 평균하여 하나의 벡터로 결합\n",
    "            final_feature = torch.mean(torch.stack(bbox_features), dim=0)\n",
    "            print(f\"Feature extracted from {image_path}, shape: {final_feature.shape}\")\n",
    "            return final_feature.cpu().detach().numpy()\n",
    "        else:\n",
    "            print(f\"No features extracted for {image_path}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"No FPN features extracted for {image_path}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering, 시각화 및 label 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm  \n",
    "from ultralytics import RTDETR\n",
    "from PIL import Image\n",
    "\n",
    "# 모델 로드 및 전처리 함수는 이전 코드 재사용\n",
    "\n",
    "# 이미지 경로 및 라벨 경로 설정\n",
    "train_image_dir = 'ultralytics_clustering/train/images_class_0'\n",
    "train_label_dir = 'ultralytics_clustering/train/labels_class_0'\n",
    "\n",
    "# 서브 클래스로 나누기 위한 클러스터링 수행 함수\n",
    "def perform_clustering(image_paths, label_paths, n_clusters=3):\n",
    "    all_features = []\n",
    "    all_bboxes = []\n",
    "    all_image_info = []\n",
    "\n",
    "    # 각 이미지에 대해 특징 추출\n",
    "    for image_path, label_path in zip(image_paths, label_paths):\n",
    "        feature_vector = extract_features(image_path, label_path)\n",
    "        if feature_vector is not None:\n",
    "            all_features.append(feature_vector)\n",
    "            all_bboxes.append(read_bboxes(label_path, *Image.open(image_path).size))  # 바운딩 박스 정보 저장\n",
    "            all_image_info.append((image_path, label_path))  # 이미지와 라벨 정보 저장\n",
    "\n",
    "    # all_features를 numpy 배열로 변환\n",
    "    all_features = np.array(all_features)\n",
    "    \n",
    "    # 3D 배열을 2D로 변환 (예: (N, C, H, W) -> (N, C*H*W))\n",
    "    if len(all_features) > 0:\n",
    "        flattened_features = all_features.reshape(all_features.shape[0], -1)  # (N, C*H*W)\n",
    "        \n",
    "        # NaN 값이 포함된 샘플을 찾기\n",
    "        nan_mask = np.isnan(flattened_features).any(axis=1)\n",
    "        \n",
    "        # NaN 값이 있는 샘플을 제거\n",
    "        flattened_features_clean = flattened_features[~nan_mask]\n",
    "        all_bboxes_clean = [bbox for bbox, is_nan in zip(all_bboxes, nan_mask) if not is_nan]\n",
    "        all_image_info_clean = [info for info, is_nan in zip(all_image_info, nan_mask) if not is_nan]\n",
    "        \n",
    "        # NaN이 모두 제거된 후 KMeans 클러스터링 수행\n",
    "        if len(flattened_features_clean) > 0:\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=7)\n",
    "            clusters = kmeans.fit_predict(flattened_features_clean)\n",
    "            return clusters, all_bboxes_clean, all_image_info_clean, flattened_features_clean\n",
    "        else:\n",
    "            raise ValueError(\"No valid features left after NaN removal.\")\n",
    "    else:\n",
    "        raise ValueError(\"No features extracted for clustering.\")\n",
    "\n",
    "\n",
    "# 모든 이미지 경로 및 라벨 경로 수집\n",
    "train_image_paths = [os.path.join(train_image_dir, img) for img in os.listdir(train_image_dir) if img.endswith('.jpg')]\n",
    "train_label_paths = [os.path.join(train_label_dir, lbl) for lbl in os.listdir(train_label_dir) if lbl.endswith('.txt')]\n",
    "\n",
    "# Train 데이터를 클러스터링\n",
    "train_clusters, train_bboxes, train_image_info, train_features = perform_clustering(train_image_paths, train_label_paths)\n",
    "\n",
    "\n",
    "# 클러스터링 결과를 바탕으로 라벨 파일 수정\n",
    "def update_labels_with_clusters(clusters, bboxes, image_info):\n",
    "    for cluster, bbox_list, (image_path, label_path) in zip(clusters, bboxes, image_info):\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        new_lines = []\n",
    "        for i, line in enumerate(lines):\n",
    "            parts = line.strip().split()\n",
    "\n",
    "            cluster_to_class = {0: 11, 1: 12, 2: 13}\n",
    "            new_class_id = cluster_to_class.get(cluster)\n",
    "            parts[0] = str(new_class_id)\n",
    "\n",
    "            new_lines.append(' '.join(parts) + '\\n')\n",
    "\n",
    "        # 변경된 내용을 다시 라벨 파일에 저장\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.writelines(new_lines)\n",
    "\n",
    "# Train 라벨 업데이트\n",
    "update_labels_with_clusters(train_clusters, train_bboxes, train_image_info)\n",
    "\n",
    "# 클러스터링 결과 시각화\n",
    "def visualize_clusters(features, clusters, n_clusters=3):\n",
    "    # 데이터 샘플 수\n",
    "    n_samples = features.shape[0]\n",
    "    \n",
    "    if n_samples <= 1:\n",
    "        print(\"ERROR: Not enough samples for clustering visualization.\")\n",
    "        return\n",
    "\n",
    "    # 차원 축소 (t-SNE 사용하여 2D로 축소)\n",
    "    perplexity = min(30, n_samples - 1)  # perplexity는 항상 n_samples보다 작아야 함\n",
    "    print(f\"Using perplexity = {perplexity} for {n_samples} samples.\")\n",
    "    \n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "    reduced_features = tsne.fit_transform(features)\n",
    "\n",
    "    # 클러스터별로 색상 지정\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = ['r', 'g', 'b']  # 클러스터 수에 맞는 색상 선택\n",
    "    for i in range(n_clusters):\n",
    "        cluster_points = reduced_features[clusters == i]\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], c=colors[i], label=f'Cluster {i}', alpha=0.6)\n",
    "\n",
    "    plt.title('Clustering Visualization (t-SNE)')\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Train 데이터의 클러스터링 결과 시각화\n",
    "visualize_clusters(train_features, train_clusters)\n",
    "\n",
    "print(\"클러스터링 및 라벨 업데이트 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 클래스 별로 TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm  \n",
    "from ultralytics import RTDETR\n",
    "from PIL import Image\n",
    "\n",
    "# 모델 로드 및 전처리 함수는 이전 코드 재사용\n",
    "\n",
    "# 이미지 경로 및 라벨 경로 설정\n",
    "train_image_dir = 'ultralytics_dataset/train(copy)/images'\n",
    "train_label_dir = 'ultralytics_dataset/train(copy)/labels'\n",
    "\n",
    "# 라벨 파일에서 클래스 정보를 추출하는 함수\n",
    "def read_classes(label_path):\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        classes = [int(line.split()[0]) for line in lines]  # 첫 번째 요소가 클래스 레이블\n",
    "    return classes\n",
    "\n",
    "# 각 이미지에 대해 특징을 추출하고 클래스별로 시각화 준비\n",
    "def extract_features_by_class(image_paths, label_paths):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_image_info = []\n",
    "\n",
    "    # 각 이미지에 대해 특징 추출\n",
    "    for image_path, label_path in zip(image_paths, label_paths):\n",
    "        feature_vector = extract_features(image_path, label_path)\n",
    "        if feature_vector is not None:\n",
    "            all_features.append(feature_vector)\n",
    "            labels = read_classes(label_path)\n",
    "            all_labels.append(labels)  # 각 이미지에 있는 모든 클래스 레이블 저장\n",
    "            all_image_info.append((image_path, label_path))  # 이미지와 라벨 정보 저장\n",
    "\n",
    "    # all_features를 numpy 배열로 변환\n",
    "    all_features = np.array(all_features)\n",
    "\n",
    "    # 3D 배열을 2D로 변환 (예: (N, C, H, W) -> (N, C*H*W))\n",
    "    if len(all_features) > 0:\n",
    "        flattened_features = all_features.reshape(all_features.shape[0], -1)  # (N, C*H*W)\n",
    "        \n",
    "        # NaN 값이 포함된 샘플을 찾기\n",
    "        nan_mask = np.isnan(flattened_features).any(axis=1)\n",
    "        \n",
    "        # NaN 값이 있는 샘플을 제거\n",
    "        flattened_features_clean = flattened_features[~nan_mask]\n",
    "        all_labels_clean = [lbl for lbl, is_nan in zip(all_labels, nan_mask) if not is_nan]\n",
    "        all_image_info_clean = [info for info, is_nan in zip(all_image_info, nan_mask) if not is_nan]\n",
    "        \n",
    "        return flattened_features_clean, all_labels_clean, all_image_info_clean\n",
    "    else:\n",
    "        raise ValueError(\"No features extracted for visualization.\")\n",
    "\n",
    "# 모든 이미지 경로 및 라벨 경로 수집\n",
    "train_image_paths = [os.path.join(train_image_dir, img) for img in os.listdir(train_image_dir) if img.endswith('.jpg')]\n",
    "train_label_paths = [os.path.join(train_label_dir, lbl) for lbl in os.listdir(train_label_dir) if lbl.endswith('.txt')]\n",
    "\n",
    "# Train 데이터에서 특징 추출 및 클래스별 라벨 수집\n",
    "train_features, train_labels, train_image_info = extract_features_by_class(train_image_paths, train_label_paths)\n",
    "\n",
    "# 특징 시각화\n",
    "def visualize_by_class(features, labels, class_names, n_components=2):\n",
    "    # 데이터를 2D로 축소 (t-SNE 사용)\n",
    "    n_samples = features.shape[0]\n",
    "    perplexity = min(30, n_samples - 1)  # perplexity는 항상 n_samples보다 작아야 함\n",
    "    \n",
    "    print(f\"Using perplexity = {perplexity} for {n_samples} samples.\")\n",
    "    tsne = TSNE(n_components=n_components, perplexity=perplexity, random_state=42)\n",
    "    reduced_features = tsne.fit_transform(features)\n",
    "\n",
    "    # 각 클래스에 대해 색상 지정\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    unique_labels = sorted(set([lbl for label_list in labels for lbl in label_list]))  # 모든 고유한 클래스 추출\n",
    "    colors = plt.cm.get_cmap('tab10', len(unique_labels))  # 고유 클래스 수에 맞는 색상 선택\n",
    "    \n",
    "    for class_idx in unique_labels:\n",
    "        class_points = [reduced_features[i] for i, label_list in enumerate(labels) if class_idx in label_list]\n",
    "        class_points = np.array(class_points)\n",
    "        plt.scatter(class_points[:, 0], class_points[:, 1], label=class_names[class_idx], alpha=0.6, color=colors(class_idx))\n",
    "\n",
    "    plt.title('Class-wise Feature Visualization (t-SNE)')\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 클래스 이름 목록 (예시로 추가, 사용자 환경에 맞게 변경)\n",
    "class_names = ['General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing']\n",
    "\n",
    "# Train 데이터의 특징을 클래스별로 시각화\n",
    "visualize_by_class(train_features, train_labels, class_names)\n",
    "\n",
    "print(\"클래스별 TSNE 시각화 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 기존 라벨 파일 경로 설정\n",
    "train_label_dir = 'ultralytics_dataset/train/labels'\n",
    "val_label_dir = 'ultralytics_dataset/val/labels'\n",
    "\n",
    "# 클러스터링된 결과가 저장된 경로\n",
    "clustered_label_dir = 'ultralytics_clustering/train/labels_class_0'\n",
    "\n",
    "# 클러스터링된 레이블을 반영하여 기존 0번 클래스를 수정하는 함수\n",
    "def update_labels_with_clustering(clustered_label_dir, original_label_dir):\n",
    "    print(\"Train label files:\", sorted(os.listdir(train_label_dir)))\n",
    "    # 클러스터링된 레이블 파일 목록\n",
    "    clustered_label_files = [f for f in os.listdir(clustered_label_dir) if f.endswith('.txt')]\n",
    "    \n",
    "    for clustered_file in clustered_label_files:\n",
    "        # 기존 라벨 파일 경로\n",
    "        original_label_path = os.path.join(original_label_dir, clustered_file)\n",
    "        clustered_label_path = os.path.join(clustered_label_dir, clustered_file)\n",
    "        \n",
    "        # 기존 라벨 파일이 존재하는지 확인\n",
    "        if not os.path.exists(original_label_path):\n",
    "            print(f\"WARNING: {original_label_path} not found. Skipping this file.\")\n",
    "            continue  # 파일이 없으면 스킵\n",
    "\n",
    "        # 클러스터링된 라벨 파일 열기\n",
    "        with open(clustered_label_path, 'r') as f_clustered:\n",
    "            clustered_lines = f_clustered.readlines()\n",
    "        \n",
    "        # 기존 라벨 파일 열기\n",
    "        with open(original_label_path, 'r') as f_original:\n",
    "            original_lines = f_original.readlines()\n",
    "\n",
    "        # 기존 라벨 파일에서 0번 클래스(General trash)만 클러스터링된 결과로 대체\n",
    "        new_lines = []\n",
    "        for original_line in original_lines:\n",
    "            parts = original_line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "\n",
    "            # 0번 클래스인 경우 클러스터링된 레이블로 대체\n",
    "            if class_id == 0:\n",
    "                # 클러스터링된 레이블과 바운딩 박스 정보로 교체\n",
    "                new_lines.extend(clustered_lines)\n",
    "            else:\n",
    "                # 다른 클래스는 그대로 유지\n",
    "                new_lines.append(original_line)\n",
    "\n",
    "        # 변경된 내용을 기존 라벨 파일에 저장\n",
    "        with open(original_label_path, 'w') as f_original:\n",
    "            f_original.writelines(new_lines)\n",
    "\n",
    "# Train 데이터의 라벨 수정\n",
    "update_labels_with_clustering(clustered_label_dir, train_label_dir)\n",
    "\n",
    "# Val 데이터의 라벨 수정\n",
    "update_labels_with_clustering(clustered_label_dir, val_label_dir)\n",
    "\n",
    "print(\"0번 클래스에 대한 라벨이 클러스터링된 결과로 수정되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(data='dataset_yaml/rtdetr.yaml', batch=8, epochs=10, imgsz=1024)\n",
    "results = model.predict(source='ultralytics_dataset/test/images', batch=8, save=True)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 저장할 폴더 경로\n",
    "save_dir = 'results'\n",
    "\n",
    "# 결과 저장 폴더가 없으면 생성\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "# COCO 형식으로 저장할 데이터를 담을 딕셔너리\n",
    "csv_data = {}\n",
    "\n",
    "# 각 결과 처리\n",
    "for result in tqdm(results):\n",
    "    image_id = result.path.split('/')[-3] + '/' + result.path.split('/')[-1]  # 파일 이름에서 image_id 추출\n",
    "    width, height = result.orig_shape[1], result.orig_shape[0]  # 이미지의 원본 크기 (width, height)\n",
    "    prediction_string = ''\n",
    "    for box in result.boxes:\n",
    "        # YOLO 형식에서 COCO 형식으로 변환 (상대 좌표를 절대 좌표로 변환)\n",
    "        bbox = box.xywh.tolist()[0]  # YOLO 형식에서 [x_center, y_center, width, height] 가져옴 (상대 좌표)\n",
    "        # 상대 좌표 (비율)를 절대 좌표 (픽셀 단위)로 변환\n",
    "        x_center, y_center, w, h = bbox\n",
    "        x_min = max(0, x_center - w / 2)\n",
    "        y_min = max(0, y_center - h / 2)\n",
    "        x_max = min(width, x_center + w / 2)\n",
    "        y_max = min(height, y_center + h / 2)\n",
    "\n",
    "        \n",
    "        category_id = int(box.cls.item())\n",
    "        score = box.conf.item()\n",
    "\n",
    "        # 11, 12, 13번 클래스를 0번으로 변경\n",
    "        if category_id in [11, 12, 13]:\n",
    "            category_id = 0\n",
    "\n",
    "        # COCO 형식으로 bbox 저장\n",
    "        bbox_str = f\"{x_min} {y_min} {x_max} {y_max}\"\n",
    "        \n",
    "        # 같은 image_id의 예측 결과를 한 줄로 합침\n",
    "        prediction_string += f\"{category_id} {score} {bbox_str} \"\n",
    "\n",
    "    # image_id에 대해 기존 예측이 있으면 이어 붙임\n",
    "    if image_id in csv_data:\n",
    "        csv_data[image_id] += prediction_string\n",
    "    else:\n",
    "        csv_data[image_id] = prediction_string\n",
    "\n",
    "# 최종적으로 image_id와 PredictionString을 CSV로 저장\n",
    "df = pd.DataFrame([{\"PredictionString\": pred_str, \"image_id\": image_id}  for image_id, pred_str in csv_data.items()])\n",
    "\n",
    "df.to_csv(os.path.join(save_dir, 'rtdetr_l_epoch10_speicific_class.csv'), index=False)\n",
    "\n",
    "print(f\"Predictions saved to {save_dir}/rtdetr_l_epoch10_speicific_class.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
