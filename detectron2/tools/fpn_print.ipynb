{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from detectron2.config import LazyConfig, instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import default_setup\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:48:33 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[10/21 11:48:34 detectron2]: \u001b[0mEnvironment info:\n",
      "-------------------------------  ----------------------------------------------------------------------------\n",
      "sys.platform                     linux\n",
      "Python                           3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "numpy                            1.22.4\n",
      "detectron2                       0.6 @/data/ephemeral/home/level2-objectdetection-cv-01/detectron2/detectron2\n",
      "Compiler                         GCC 9.4\n",
      "CUDA compiler                    not available\n",
      "DETECTRON2_ENV_MODULE            <not set>\n",
      "PyTorch                          1.12.1+cu116 @/opt/conda/lib/python3.10/site-packages/torch\n",
      "PyTorch debug build              False\n",
      "torch._C._GLIBCXX_USE_CXX11_ABI  False\n",
      "GPU available                    Yes\n",
      "GPU 0                            Tesla V100-SXM2-32GB (arch=7.0)\n",
      "Driver version                   535.161.08\n",
      "CUDA_HOME                        None - invalid!\n",
      "Pillow                           9.4.0\n",
      "torchvision                      0.13.1+cu116 @/opt/conda/lib/python3.10/site-packages/torchvision\n",
      "torchvision arch flags           /opt/conda/lib/python3.10/site-packages/torchvision/_C.so\n",
      "fvcore                           0.1.5.post20221221\n",
      "iopath                           0.1.9\n",
      "cv2                              4.8.1\n",
      "-------------------------------  ----------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.6\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "\u001b[32m[10/21 11:48:34 detectron2]: \u001b[0mCommand line arguments: \n",
      "\u001b[32m[10/21 11:48:34 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[10/21 11:48:34 d2.utils.env]: \u001b[0mUsing a generated random seed 34823952\n"
     ]
    }
   ],
   "source": [
    "cfg = LazyConfig.load(\"/data/ephemeral/home/level2-objectdetection-cv-01/detectron2/projects/ViTDet/configs/COCO/cascade_mask_rcnn_vitdet_b_100ep.py\")\n",
    "default_setup(cfg, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    register_coco_instances('coco_trash_train', {}, '/data/ephemeral/home/dataset/train_80.json', '/data/ephemeral/home/dataset')\n",
    "except AssertionError:\n",
    "    pass\n",
    "try:\n",
    "    register_coco_instances('coco_trash_test', {}, '/data/ephemeral/home/dataset/val_20.json', '/data/ephemeral/home/dataset')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                                                        \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:48:38 d2.data.datasets.coco]: \u001b[0mLoaded 3914 images in COCO format from /data/ephemeral/home/dataset/train_80.json\n",
      "\u001b[32m[10/21 11:48:39 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 3914 images left.\n",
      "\u001b[32m[10/21 11:48:39 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 3161         |    Paper    | 5115         | Paper pack | 706          |\n",
      "|     Metal     | 769          |    Glass    | 835          |  Plastic   | 2350         |\n",
      "|   Styrofoam   | 1026         | Plastic bag | 4151         |  Battery   | 143          |\n",
      "|   Clothing    | 377          |             |              |            |              |\n",
      "|     total     | 18633        |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/21 11:48:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/21 11:48:39 d2.data.common]: \u001b[0mSerializing 3914 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:48:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.81 MiB\n",
      "\u001b[32m[10/21 11:48:39 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n"
     ]
    }
   ],
   "source": [
    "model = instantiate(cfg.model)\n",
    "model.to(cfg.train.device)\n",
    "train_loader = instantiate(cfg.dataloader.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleFeaturePyramid(\n",
       "  (simfp_2): Sequential(\n",
       "    (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): LayerNorm()\n",
       "    (2): GELU(approximate=none)\n",
       "    (3): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (4): Conv2d(\n",
       "      192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (5): Conv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "  )\n",
       "  (simfp_3): Sequential(\n",
       "    (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): Conv2d(\n",
       "      384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (2): Conv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "  )\n",
       "  (simfp_4): Sequential(\n",
       "    (0): Conv2d(\n",
       "      768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (1): Conv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "  )\n",
       "  (simfp_5): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(\n",
       "      768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (2): Conv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "  )\n",
       "  (net): ViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.009)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.018)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.027)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.036)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.045)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.055)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.064)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.073)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.082)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.091)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate=none)\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (top_block): LastLevelMaxPool()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = model.preprocess_image(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1024, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.backbone(image.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[156.8000, 290.3000, 751.1000, 770.3000]])), gt_classes: tensor([5])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]['instances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p2  :  torch.Size([2, 256, 256, 256])\n",
      "p3  :  torch.Size([2, 256, 128, 128])\n",
      "p4  :  torch.Size([2, 256, 64, 64])\n",
      "p5  :  torch.Size([2, 256, 32, 32])\n",
      "p6  :  torch.Size([2, 256, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "for i in test.keys():\n",
    "    print(i, \" : \",test[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 16, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['p6'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_instances = [x[\"instances\"].to(model.device) for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[156.8000, 290.3000, 751.1000, 770.3000]], device='cuda:0')), gt_classes: tensor([5], device='cuda:0')]),\n",
       " Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[202., 128., 647., 815.]], device='cuda:0')), gt_classes: tensor([2], device='cuda:0')])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p2', 'p3', 'p4', 'p5', 'p6']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.proposal_generator.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [test[f] for f in model.proposal_generator.in_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p2', 'p3', 'p4', 'p5', 'p6']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.proposal_generator.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p2', 'p3', 'p4', 'p5']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roi_heads.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "anchors = model.proposal_generator.anchor_generator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :  torch.Size([196608, 4])\n",
      " :  torch.Size([49152, 4])\n",
      " :  torch.Size([12288, 4])\n",
      " :  torch.Size([3072, 4])\n",
      " :  torch.Size([768, 4])\n"
     ]
    }
   ],
   "source": [
    "for i in anchors:\n",
    "    print( \" : \",i.tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.proposal_generator(image, test, gt_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_objectness_logits, pred_anchor_deltas = model.proposal_generator.rpn_head(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 256, 256])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_objectness_logits[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 128, 128])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_objectness_logits[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_objectness_logits = [\n",
    "    # (N, A, Hi, Wi) -> (N, Hi, Wi, A) -> (N, Hi*Wi*A)\n",
    "    score.permute(0, 2, 3, 1).flatten(1)\n",
    "    for score in pred_objectness_logits\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_anchor_deltas = [\n",
    "# (N, A*B, Hi, Wi) -> (N, A, B, Hi, Wi) -> (N, Hi, Wi, A, B) -> (N, Hi*Wi*A, B)\n",
    "x.view(x.shape[0], -1, model.proposal_generator.anchor_generator.box_dim, x.shape[-2], x.shape[-1])\n",
    ".permute(0, 3, 4, 1, 2)\n",
    ".flatten(1, -2)\n",
    "for x in pred_anchor_deltas\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 196608, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_anchor_deltas[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_labels, gt_boxes = model.proposal_generator.label_and_sample_anchors(anchors, gt_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1024, 1024), (1024, 1024)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.image_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = model.proposal_generator.predict_proposals(\n",
    "    anchors, pred_objectness_logits, pred_anchor_deltas, image.image_sizes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instances(num_instances=1000, image_height=1024, image_width=1024, fields=[proposal_boxes: Boxes(tensor([[550.5684, 680.6083, 615.2935, 745.9509],\n",
       "        [935.3654, 232.6556, 967.7941, 264.0651],\n",
       "        [923.0459, 243.5042, 954.9937, 275.3983],\n",
       "        ...,\n",
       "        [859.0336, 708.1061, 891.4944, 739.9067],\n",
       "        [883.4612, 284.5491, 915.4044, 316.4648],\n",
       "        [807.5496, 840.6591, 872.2675, 904.8127]], device='cuda:0')), objectness_logits: tensor([0.0551, 0.0531, 0.0519, 0.0503, 0.0500, 0.0487, 0.0487, 0.0482, 0.0481,\n",
       "        0.0480, 0.0472, 0.0471, 0.0471, 0.0467, 0.0465, 0.0464, 0.0463, 0.0463,\n",
       "        0.0462, 0.0459, 0.0453, 0.0450, 0.0448, 0.0448, 0.0448, 0.0447, 0.0446,\n",
       "        0.0444, 0.0444, 0.0444, 0.0443, 0.0442, 0.0441, 0.0440, 0.0440, 0.0439,\n",
       "        0.0436, 0.0436, 0.0435, 0.0435, 0.0433, 0.0432, 0.0431, 0.0431, 0.0429,\n",
       "        0.0428, 0.0428, 0.0426, 0.0426, 0.0426, 0.0425, 0.0423, 0.0423, 0.0423,\n",
       "        0.0423, 0.0422, 0.0421, 0.0421, 0.0421, 0.0420, 0.0419, 0.0419, 0.0419,\n",
       "        0.0418, 0.0416, 0.0416, 0.0416, 0.0415, 0.0415, 0.0415, 0.0414, 0.0413,\n",
       "        0.0413, 0.0413, 0.0413, 0.0413, 0.0412, 0.0412, 0.0412, 0.0412, 0.0411,\n",
       "        0.0411, 0.0411, 0.0410, 0.0410, 0.0410, 0.0409, 0.0408, 0.0408, 0.0407,\n",
       "        0.0407, 0.0406, 0.0406, 0.0406, 0.0406, 0.0406, 0.0405, 0.0405, 0.0405,\n",
       "        0.0405, 0.0405, 0.0405, 0.0405, 0.0404, 0.0404, 0.0404, 0.0404, 0.0404,\n",
       "        0.0404, 0.0404, 0.0404, 0.0403, 0.0402, 0.0402, 0.0401, 0.0401, 0.0401,\n",
       "        0.0400, 0.0400, 0.0400, 0.0400, 0.0399, 0.0399, 0.0399, 0.0399, 0.0399,\n",
       "        0.0399, 0.0399, 0.0399, 0.0398, 0.0398, 0.0397, 0.0397, 0.0396, 0.0396,\n",
       "        0.0396, 0.0396, 0.0395, 0.0395, 0.0395, 0.0395, 0.0394, 0.0394, 0.0394,\n",
       "        0.0394, 0.0394, 0.0394, 0.0393, 0.0393, 0.0393, 0.0393, 0.0393, 0.0393,\n",
       "        0.0392, 0.0392, 0.0392, 0.0392, 0.0392, 0.0392, 0.0392, 0.0392, 0.0392,\n",
       "        0.0392, 0.0392, 0.0392, 0.0391, 0.0391, 0.0391, 0.0391, 0.0391, 0.0391,\n",
       "        0.0391, 0.0391, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390,\n",
       "        0.0390, 0.0390, 0.0389, 0.0389, 0.0389, 0.0389, 0.0389, 0.0389, 0.0389,\n",
       "        0.0389, 0.0389, 0.0389, 0.0389, 0.0389, 0.0388, 0.0388, 0.0388, 0.0388,\n",
       "        0.0388, 0.0388, 0.0388, 0.0388, 0.0388, 0.0388, 0.0388, 0.0388, 0.0388,\n",
       "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0386, 0.0386, 0.0385, 0.0385,\n",
       "        0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0384, 0.0384,\n",
       "        0.0384, 0.0384, 0.0384, 0.0384, 0.0384, 0.0383, 0.0383, 0.0383, 0.0383,\n",
       "        0.0383, 0.0383, 0.0383, 0.0382, 0.0382, 0.0382, 0.0382, 0.0382, 0.0382,\n",
       "        0.0382, 0.0381, 0.0381, 0.0381, 0.0381, 0.0381, 0.0381, 0.0381, 0.0381,\n",
       "        0.0381, 0.0381, 0.0381, 0.0381, 0.0381, 0.0381, 0.0381, 0.0380, 0.0380,\n",
       "        0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0379, 0.0379,\n",
       "        0.0379, 0.0379, 0.0379, 0.0378, 0.0378, 0.0378, 0.0378, 0.0378, 0.0378,\n",
       "        0.0377, 0.0377, 0.0377, 0.0377, 0.0377, 0.0377, 0.0377, 0.0376, 0.0376,\n",
       "        0.0376, 0.0376, 0.0376, 0.0376, 0.0376, 0.0376, 0.0376, 0.0376, 0.0375,\n",
       "        0.0375, 0.0375, 0.0375, 0.0375, 0.0375, 0.0375, 0.0374, 0.0374, 0.0374,\n",
       "        0.0374, 0.0374, 0.0374, 0.0374, 0.0374, 0.0373, 0.0373, 0.0373, 0.0373,\n",
       "        0.0373, 0.0373, 0.0373, 0.0373, 0.0372, 0.0372, 0.0372, 0.0372, 0.0372,\n",
       "        0.0372, 0.0372, 0.0372, 0.0372, 0.0372, 0.0371, 0.0371, 0.0371, 0.0371,\n",
       "        0.0371, 0.0371, 0.0371, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
       "        0.0370, 0.0370, 0.0369, 0.0369, 0.0369, 0.0369, 0.0369, 0.0369, 0.0369,\n",
       "        0.0369, 0.0369, 0.0369, 0.0369, 0.0369, 0.0368, 0.0368, 0.0368, 0.0368,\n",
       "        0.0368, 0.0368, 0.0368, 0.0368, 0.0368, 0.0368, 0.0368, 0.0368, 0.0368,\n",
       "        0.0367, 0.0367, 0.0367, 0.0367, 0.0367, 0.0367, 0.0367, 0.0367, 0.0367,\n",
       "        0.0367, 0.0367, 0.0367, 0.0367, 0.0367, 0.0366, 0.0366, 0.0366, 0.0366,\n",
       "        0.0366, 0.0366, 0.0366, 0.0366, 0.0366, 0.0366, 0.0366, 0.0365, 0.0365,\n",
       "        0.0365, 0.0365, 0.0365, 0.0365, 0.0365, 0.0365, 0.0365, 0.0365, 0.0365,\n",
       "        0.0365, 0.0365, 0.0365, 0.0364, 0.0364, 0.0364, 0.0364, 0.0364, 0.0364,\n",
       "        0.0364, 0.0363, 0.0363, 0.0363, 0.0363, 0.0363, 0.0363, 0.0363, 0.0363,\n",
       "        0.0363, 0.0363, 0.0363, 0.0363, 0.0363, 0.0363, 0.0363, 0.0362, 0.0362,\n",
       "        0.0362, 0.0362, 0.0362, 0.0362, 0.0362, 0.0362, 0.0361, 0.0361, 0.0361,\n",
       "        0.0361, 0.0361, 0.0361, 0.0361, 0.0361, 0.0361, 0.0361, 0.0361, 0.0361,\n",
       "        0.0361, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
       "        0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0359,\n",
       "        0.0359, 0.0359, 0.0359, 0.0359, 0.0359, 0.0359, 0.0359, 0.0359, 0.0359,\n",
       "        0.0359, 0.0359, 0.0359, 0.0359, 0.0359, 0.0359, 0.0359, 0.0358, 0.0358,\n",
       "        0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358,\n",
       "        0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358,\n",
       "        0.0358, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357,\n",
       "        0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357,\n",
       "        0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0356,\n",
       "        0.0356, 0.0356, 0.0356, 0.0356, 0.0355, 0.0355, 0.0355, 0.0355, 0.0355,\n",
       "        0.0355, 0.0355, 0.0355, 0.0355, 0.0355, 0.0355, 0.0355, 0.0355, 0.0354,\n",
       "        0.0354, 0.0354, 0.0354, 0.0354, 0.0354, 0.0354, 0.0354, 0.0354, 0.0354,\n",
       "        0.0354, 0.0354, 0.0354, 0.0354, 0.0354, 0.0354, 0.0354, 0.0354, 0.0354,\n",
       "        0.0354, 0.0353, 0.0353, 0.0353, 0.0353, 0.0353, 0.0353, 0.0353, 0.0353,\n",
       "        0.0353, 0.0353, 0.0353, 0.0353, 0.0353, 0.0353, 0.0353, 0.0353, 0.0353,\n",
       "        0.0353, 0.0353, 0.0352, 0.0352, 0.0352, 0.0352, 0.0352, 0.0352, 0.0352,\n",
       "        0.0352, 0.0352, 0.0352, 0.0352, 0.0352, 0.0352, 0.0351, 0.0351, 0.0351,\n",
       "        0.0351, 0.0351, 0.0351, 0.0351, 0.0351, 0.0351, 0.0351, 0.0351, 0.0351,\n",
       "        0.0351, 0.0351, 0.0351, 0.0351, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350,\n",
       "        0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0349,\n",
       "        0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349,\n",
       "        0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0349, 0.0348, 0.0348,\n",
       "        0.0348, 0.0348, 0.0348, 0.0348, 0.0348, 0.0348, 0.0348, 0.0348, 0.0348,\n",
       "        0.0348, 0.0348, 0.0348, 0.0348, 0.0348, 0.0348, 0.0348, 0.0348, 0.0348,\n",
       "        0.0348, 0.0348, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347,\n",
       "        0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347,\n",
       "        0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0346,\n",
       "        0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346,\n",
       "        0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346,\n",
       "        0.0346, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345,\n",
       "        0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345,\n",
       "        0.0345, 0.0345, 0.0345, 0.0345, 0.0344, 0.0344, 0.0344, 0.0344, 0.0344,\n",
       "        0.0344, 0.0344, 0.0344, 0.0344, 0.0344, 0.0344, 0.0344, 0.0344, 0.0344,\n",
       "        0.0344, 0.0344, 0.0344, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343,\n",
       "        0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343,\n",
       "        0.0343, 0.0343, 0.0343, 0.0343, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
       "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
       "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0341, 0.0341, 0.0341, 0.0341,\n",
       "        0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341,\n",
       "        0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341,\n",
       "        0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341, 0.0341,\n",
       "        0.0341, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
       "        0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
       "        0.0340, 0.0340, 0.0339, 0.0339, 0.0339, 0.0339, 0.0339, 0.0339, 0.0339,\n",
       "        0.0339, 0.0339, 0.0339, 0.0339, 0.0339, 0.0339, 0.0339, 0.0339, 0.0339,\n",
       "        0.0339, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338,\n",
       "        0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0337, 0.0337, 0.0337,\n",
       "        0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337,\n",
       "        0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337,\n",
       "        0.0337, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336,\n",
       "        0.0336, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336,\n",
       "        0.0336, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336, 0.0336,\n",
       "        0.0336, 0.0336, 0.0336, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335,\n",
       "        0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335,\n",
       "        0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335,\n",
       "        0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335, 0.0335,\n",
       "        0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334,\n",
       "        0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334,\n",
       "        0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334, 0.0334,\n",
       "        0.0334, 0.0334, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333,\n",
       "        0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333,\n",
       "        0.0333], device='cuda:0')])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.roi_heads.label_and_sample_proposals(proposals,gt_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roi_heads.proposal_append_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposals = model.roi_heads.add_ground_truth_to_proposals(gt_instances,proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.modeling.proposal_generator.proposal_utils import add_ground_truth_to_proposals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = add_ground_truth_to_proposals(gt_instances,proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Instances(num_instances=1001, image_height=1024, image_width=1024, fields=[proposal_boxes: Boxes(tensor([[550.5684, 680.6083, 615.2935, 745.9509],\n",
       "         [935.3654, 232.6556, 967.7941, 264.0651],\n",
       "         [923.0459, 243.5042, 954.9937, 275.3983],\n",
       "         ...,\n",
       "         [883.4612, 284.5491, 915.4044, 316.4648],\n",
       "         [807.5496, 840.6591, 872.2675, 904.8127],\n",
       "         [156.8000, 290.3000, 751.1000, 770.3000]], device='cuda:0')), objectness_logits: tensor([ 0.0551,  0.0531,  0.0519,  ...,  0.0333,  0.0333, 23.0259],\n",
       "        device='cuda:0')]),\n",
       " Instances(num_instances=1001, image_height=1024, image_width=1024, fields=[proposal_boxes: Boxes(tensor([[ 116.6944,  501.0135,  161.3426,  523.3392],\n",
       "         [ 727.5382, 1000.6201,  760.1986, 1024.0000],\n",
       "         [ 919.3065,  824.3824,  951.7719,  856.6013],\n",
       "         ...,\n",
       "         [ 975.1458,  403.9811, 1007.5734,  436.6864],\n",
       "         [ 479.5677,  947.8969,  512.1809,  980.1924],\n",
       "         [ 202.0000,  128.0000,  647.0000,  815.0000]], device='cuda:0')), objectness_logits: tensor([ 0.0555,  0.0525,  0.0521,  ...,  0.0353,  0.0353, 23.0259],\n",
       "        device='cuda:0')])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import  pairwise_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_with_gt = []\n",
    "\n",
    "num_fg_samples = []\n",
    "num_bg_samples = []\n",
    "\n",
    "\n",
    "for proposals_per_image, targets_per_image in zip(proposals, gt_instances):\n",
    "    has_gt = len(targets_per_image) > 0\n",
    "    match_quality_matrix = pairwise_iou(\n",
    "        targets_per_image.gt_boxes, proposals_per_image.proposal_boxes\n",
    "    )\n",
    "    matched_idxs, matched_labels = model.roi_heads.proposal_matcher(match_quality_matrix)\n",
    "    sampled_idxs, gt_classes = model.roi_heads._sample_proposals(\n",
    "        matched_idxs, matched_labels, targets_per_image.gt_classes\n",
    "    )\n",
    "\n",
    "    # Set target attributes of the sampled proposals:\n",
    "    proposals_per_image = proposals_per_image[sampled_idxs]\n",
    "    proposals_per_image.gt_classes = gt_classes\n",
    "\n",
    "    if has_gt:\n",
    "        sampled_targets = matched_idxs[sampled_idxs]\n",
    "        # We index all the attributes of targets that start with \"gt_\"\n",
    "        # and have not been added to proposals yet (=\"gt_classes\").\n",
    "        # NOTE: here the indexing waste some compute, because heads\n",
    "        # like masks, keypoints, etc, will filter the proposals again,\n",
    "        # (by foreground/background, or number of keypoints in the image, etc)\n",
    "        # so we essentially index the data twice.\n",
    "        for trg_name, trg_value in targets_per_image.get_fields().items():\n",
    "            if trg_name.startswith(\"gt_\") and not proposals_per_image.has(trg_name):\n",
    "                proposals_per_image.set(trg_name, trg_value[sampled_targets])\n",
    "    # If no GT is given in the image, we don't know what a dummy gt value can be.\n",
    "    # Therefore the returned proposals won't have any gt_* fields, except for a\n",
    "    # gt_classes full of background label.\n",
    "\n",
    "    num_bg_samples.append((gt_classes == model.roi_heads.num_classes).sum().item())\n",
    "    num_fg_samples.append(gt_classes.numel() - num_bg_samples[-1])\n",
    "    proposals_with_gt.append(proposals_per_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Instances(num_instances=512, image_height=1024, image_width=1024, fields=[proposal_boxes: Boxes(tensor([[ 156.8000,  290.3000,  751.1000,  770.3000],\n",
       "         [ 983.9510,  456.3400, 1016.5684,  487.5888],\n",
       "         [ 715.0809,  532.2385,  747.4502,  563.6819],\n",
       "         ...,\n",
       "         [  39.3918,  440.4337,   71.6111,  471.7375],\n",
       "         [ 351.5990,  713.0428,  383.7295,  744.7601],\n",
       "         [ 551.4412,  840.4567,  616.1255,  904.6942]], device='cuda:0')), objectness_logits: tensor([23.0259,  0.0340,  0.0353,  0.0334,  0.0333,  0.0388,  0.0402,  0.0333,\n",
       "          0.0348,  0.0345,  0.0343,  0.0419,  0.0337,  0.0351,  0.0421,  0.0376,\n",
       "          0.0347,  0.0401,  0.0379,  0.0345,  0.0333,  0.0354,  0.0362,  0.0335,\n",
       "          0.0369,  0.0359,  0.0344,  0.0393,  0.0339,  0.0362,  0.0359,  0.0345,\n",
       "          0.0465,  0.0340,  0.0396,  0.0374,  0.0358,  0.0383,  0.0343,  0.0340,\n",
       "          0.0353,  0.0345,  0.0376,  0.0335,  0.0336,  0.0372,  0.0337,  0.0333,\n",
       "          0.0334,  0.0342,  0.0336,  0.0393,  0.0333,  0.0366,  0.0390,  0.0348,\n",
       "          0.0390,  0.0361,  0.0344,  0.0335,  0.0369,  0.0367,  0.0366,  0.0343,\n",
       "          0.0341,  0.0358,  0.0423,  0.0399,  0.0349,  0.0450,  0.0341,  0.0376,\n",
       "          0.0399,  0.0342,  0.0346,  0.0391,  0.0348,  0.0336,  0.0347,  0.0399,\n",
       "          0.0363,  0.0435,  0.0361,  0.0358,  0.0360,  0.0335,  0.0356,  0.0405,\n",
       "          0.0415,  0.0355,  0.0441,  0.0350,  0.0335,  0.0414,  0.0421,  0.0338,\n",
       "          0.0359,  0.0345,  0.0360,  0.0337,  0.0354,  0.0339,  0.0383,  0.0363,\n",
       "          0.0342,  0.0353,  0.0393,  0.0341,  0.0343,  0.0373,  0.0387,  0.0338,\n",
       "          0.0353,  0.0353,  0.0405,  0.0370,  0.0413,  0.0341,  0.0370,  0.0339,\n",
       "          0.0381,  0.0349,  0.0394,  0.0337,  0.0346,  0.0354,  0.0339,  0.0339,\n",
       "          0.0357,  0.0334,  0.0334,  0.0369,  0.0364,  0.0383,  0.0384,  0.0347,\n",
       "          0.0360,  0.0336,  0.0349,  0.0366,  0.0350,  0.0359,  0.0360,  0.0347,\n",
       "          0.0336,  0.0415,  0.0337,  0.0392,  0.0345,  0.0378,  0.0355,  0.0336,\n",
       "          0.0335,  0.0354,  0.0385,  0.0351,  0.0404,  0.0342,  0.0380,  0.0355,\n",
       "          0.0358,  0.0393,  0.0337,  0.0387,  0.0350,  0.0348,  0.0345,  0.0354,\n",
       "          0.0376,  0.0339,  0.0348,  0.0347,  0.0398,  0.0394,  0.0428,  0.0379,\n",
       "          0.0335,  0.0372,  0.0376,  0.0343,  0.0376,  0.0374,  0.0347,  0.0342,\n",
       "          0.0338,  0.0396,  0.0346,  0.0334,  0.0335,  0.0389,  0.0371,  0.0340,\n",
       "          0.0341,  0.0337,  0.0429,  0.0341,  0.0388,  0.0383,  0.0347,  0.0353,\n",
       "          0.0382,  0.0381,  0.0356,  0.0365,  0.0392,  0.0348,  0.0338,  0.0405,\n",
       "          0.0356,  0.0334,  0.0336,  0.0369,  0.0369,  0.0404,  0.0342,  0.0346,\n",
       "          0.0462,  0.0348,  0.0367,  0.0379,  0.0336,  0.0388,  0.0345,  0.0365,\n",
       "          0.0334,  0.0362,  0.0384,  0.0344,  0.0334,  0.0347,  0.0369,  0.0378,\n",
       "          0.0375,  0.0351,  0.0334,  0.0334,  0.0360,  0.0334,  0.0357,  0.0373,\n",
       "          0.0372,  0.0335,  0.0335,  0.0347,  0.0340,  0.0342,  0.0375,  0.0333,\n",
       "          0.0341,  0.0423,  0.0467,  0.0374,  0.0340,  0.0365,  0.0531,  0.0357,\n",
       "          0.0334,  0.0487,  0.0416,  0.0355,  0.0373,  0.0368,  0.0394,  0.0392,\n",
       "          0.0372,  0.0388,  0.0335,  0.0373,  0.0349,  0.0425,  0.0348,  0.0349,\n",
       "          0.0337,  0.0388,  0.0335,  0.0446,  0.0351,  0.0413,  0.0367,  0.0348,\n",
       "          0.0411,  0.0348,  0.0356,  0.0342,  0.0341,  0.0334,  0.0337,  0.0356,\n",
       "          0.0340,  0.0503,  0.0362,  0.0336,  0.0358,  0.0385,  0.0348,  0.0487,\n",
       "          0.0342,  0.0378,  0.0335,  0.0352,  0.0355,  0.0336,  0.0358,  0.0359,\n",
       "          0.0344,  0.0357,  0.0354,  0.0357,  0.0385,  0.0368,  0.0348,  0.0358,\n",
       "          0.0391,  0.0339,  0.0341,  0.0340,  0.0355,  0.0352,  0.0551,  0.0426,\n",
       "          0.0339,  0.0344,  0.0406,  0.0342,  0.0385,  0.0463,  0.0372,  0.0346,\n",
       "          0.0431,  0.0397,  0.0359,  0.0360,  0.0341,  0.0372,  0.0356,  0.0353,\n",
       "          0.0333,  0.0459,  0.0382,  0.0354,  0.0404,  0.0389,  0.0413,  0.0426,\n",
       "          0.0351,  0.0392,  0.0423,  0.0387,  0.0389,  0.0368,  0.0359,  0.0357,\n",
       "          0.0358,  0.0336,  0.0333,  0.0383,  0.0345,  0.0368,  0.0344,  0.0376,\n",
       "          0.0359,  0.0375,  0.0335,  0.0343,  0.0345,  0.0365,  0.0378,  0.0357,\n",
       "          0.0385,  0.0382,  0.0399,  0.0346,  0.0336,  0.0340,  0.0400,  0.0350,\n",
       "          0.0412,  0.0344,  0.0343,  0.0355,  0.0348,  0.0361,  0.0359,  0.0380,\n",
       "          0.0346,  0.0338,  0.0339,  0.0334,  0.0405,  0.0343,  0.0347,  0.0384,\n",
       "          0.0386,  0.0350,  0.0335,  0.0362,  0.0347,  0.0381,  0.0410,  0.0380,\n",
       "          0.0364,  0.0346,  0.0336,  0.0392,  0.0410,  0.0370,  0.0381,  0.0373,\n",
       "          0.0380,  0.0342,  0.0366,  0.0395,  0.0355,  0.0333,  0.0346,  0.0337,\n",
       "          0.0337,  0.0404,  0.0448,  0.0341,  0.0351,  0.0363,  0.0338,  0.0336,\n",
       "          0.0368,  0.0363,  0.0440,  0.0343,  0.0361,  0.0357,  0.0404,  0.0349,\n",
       "          0.0431,  0.0370,  0.0349,  0.0357,  0.0381,  0.0345,  0.0337,  0.0357,\n",
       "          0.0440,  0.0384,  0.0335,  0.0381,  0.0335,  0.0389,  0.0369,  0.0410,\n",
       "          0.0343,  0.0377,  0.0365,  0.0367,  0.0352,  0.0353,  0.0367,  0.0363,\n",
       "          0.0337,  0.0382,  0.0423,  0.0351,  0.0381,  0.0352,  0.0412,  0.0335,\n",
       "          0.0352,  0.0352,  0.0418,  0.0342,  0.0334,  0.0340,  0.0373,  0.0362,\n",
       "          0.0363,  0.0388,  0.0401,  0.0406,  0.0348,  0.0405,  0.0358,  0.0337,\n",
       "          0.0339,  0.0363,  0.0336,  0.0382,  0.0336,  0.0353,  0.0471,  0.0348,\n",
       "          0.0351,  0.0371,  0.0335,  0.0389,  0.0349,  0.0370,  0.0367,  0.0334,\n",
       "          0.0350,  0.0347,  0.0381,  0.0351,  0.0385,  0.0336,  0.0363,  0.0377,\n",
       "          0.0386,  0.0375,  0.0333,  0.0367,  0.0348,  0.0354,  0.0376,  0.0380],\n",
       "        device='cuda:0'), gt_classes: tensor([ 5, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80], device='cuda:0'), gt_boxes: Boxes(tensor([[156.8000, 290.3000, 751.1000, 770.3000],\n",
       "         [156.8000, 290.3000, 751.1000, 770.3000],\n",
       "         [156.8000, 290.3000, 751.1000, 770.3000],\n",
       "         ...,\n",
       "         [156.8000, 290.3000, 751.1000, 770.3000],\n",
       "         [156.8000, 290.3000, 751.1000, 770.3000],\n",
       "         [156.8000, 290.3000, 751.1000, 770.3000]], device='cuda:0'))]),\n",
       " Instances(num_instances=512, image_height=1024, image_width=1024, fields=[proposal_boxes: Boxes(tensor([[202.0000, 128.0000, 647.0000, 815.0000],\n",
       "         [126.8290, 813.1934, 159.3536, 844.4293],\n",
       "         [135.1260, 561.2688, 313.6719, 649.1256],\n",
       "         ...,\n",
       "         [229.8246, 808.6747, 297.0748, 872.5771],\n",
       "         [ 37.6119, 628.9191,  82.6540, 651.3278],\n",
       "         [630.0667, 372.5196, 675.3264, 394.3167]], device='cuda:0')), objectness_logits: tensor([23.0259,  0.0385,  0.0374,  0.0381,  0.0420,  0.0355,  0.0363,  0.0378,\n",
       "          0.0366,  0.0361,  0.0362,  0.0384,  0.0392,  0.0379,  0.0383,  0.0378,\n",
       "          0.0373,  0.0400,  0.0371,  0.0359,  0.0354,  0.0362,  0.0449,  0.0400,\n",
       "          0.0364,  0.0360,  0.0362,  0.0355,  0.0417,  0.0430,  0.0374,  0.0353,\n",
       "          0.0358,  0.0379,  0.0377,  0.0355,  0.0374,  0.0398,  0.0360,  0.0362,\n",
       "          0.0386,  0.0357,  0.0416,  0.0424,  0.0419,  0.0371,  0.0373,  0.0360,\n",
       "          0.0359,  0.0371,  0.0384,  0.0439,  0.0382,  0.0368,  0.0373,  0.0489,\n",
       "          0.0496,  0.0361,  0.0369,  0.0397,  0.0375,  0.0372,  0.0408,  0.0416,\n",
       "          0.0388,  0.0435,  0.0356,  0.0381,  0.0366,  0.0360,  0.0361,  0.0397,\n",
       "          0.0361,  0.0354,  0.0371,  0.0473,  0.0485,  0.0371,  0.0469,  0.0394,\n",
       "          0.0390,  0.0437,  0.0377,  0.0355,  0.0355,  0.0363,  0.0356,  0.0510,\n",
       "          0.0370,  0.0424,  0.0376,  0.0365,  0.0388,  0.0364,  0.0369,  0.0373,\n",
       "          0.0375,  0.0366,  0.0366,  0.0421,  0.0365,  0.0363,  0.0423,  0.0362,\n",
       "          0.0436,  0.0396,  0.0353,  0.0381,  0.0379,  0.0412,  0.0367,  0.0366,\n",
       "          0.0372,  0.0357,  0.0391,  0.0376,  0.0400,  0.0379,  0.0356,  0.0434,\n",
       "          0.0412,  0.0396,  0.0368,  0.0375,  0.0405,  0.0364,  0.0367,  0.0400,\n",
       "          0.0354,  0.0362,  0.0475,  0.0387,  0.0357,  0.0387,  0.0384,  0.0375,\n",
       "          0.0437,  0.0411,  0.0403,  0.0379,  0.0394,  0.0370,  0.0418,  0.0382,\n",
       "          0.0441,  0.0387,  0.0367,  0.0381,  0.0355,  0.0362,  0.0467,  0.0359,\n",
       "          0.0369,  0.0367,  0.0360,  0.0376,  0.0369,  0.0363,  0.0389,  0.0376,\n",
       "          0.0372,  0.0418,  0.0393,  0.0355,  0.0355,  0.0438,  0.0370,  0.0392,\n",
       "          0.0372,  0.0364,  0.0394,  0.0376,  0.0354,  0.0391,  0.0359,  0.0373,\n",
       "          0.0365,  0.0388,  0.0377,  0.0371,  0.0357,  0.0380,  0.0419,  0.0354,\n",
       "          0.0364,  0.0366,  0.0387,  0.0405,  0.0415,  0.0407,  0.0363,  0.0395,\n",
       "          0.0357,  0.0389,  0.0356,  0.0415,  0.0360,  0.0354,  0.0421,  0.0380,\n",
       "          0.0367,  0.0363,  0.0356,  0.0372,  0.0395,  0.0353,  0.0361,  0.0404,\n",
       "          0.0381,  0.0402,  0.0377,  0.0368,  0.0384,  0.0354,  0.0446,  0.0435,\n",
       "          0.0360,  0.0356,  0.0357,  0.0418,  0.0396,  0.0386,  0.0362,  0.0369,\n",
       "          0.0391,  0.0368,  0.0400,  0.0401,  0.0359,  0.0405,  0.0400,  0.0368,\n",
       "          0.0398,  0.0407,  0.0354,  0.0373,  0.0363,  0.0356,  0.0371,  0.0376,\n",
       "          0.0362,  0.0460,  0.0356,  0.0359,  0.0370,  0.0380,  0.0427,  0.0394,\n",
       "          0.0358,  0.0362,  0.0388,  0.0428,  0.0372,  0.0456,  0.0353,  0.0366,\n",
       "          0.0414,  0.0408,  0.0380,  0.0367,  0.0362,  0.0406,  0.0353,  0.0354,\n",
       "          0.0387,  0.0355,  0.0367,  0.0375,  0.0367,  0.0398,  0.0380,  0.0387,\n",
       "          0.0357,  0.0376,  0.0447,  0.0391,  0.0358,  0.0358,  0.0389,  0.0426,\n",
       "          0.0366,  0.0357,  0.0389,  0.0357,  0.0392,  0.0379,  0.0367,  0.0377,\n",
       "          0.0356,  0.0370,  0.0369,  0.0446,  0.0427,  0.0366,  0.0369,  0.0390,\n",
       "          0.0387,  0.0362,  0.0378,  0.0378,  0.0363,  0.0409,  0.0370,  0.0391,\n",
       "          0.0358,  0.0399,  0.0381,  0.0403,  0.0354,  0.0390,  0.0377,  0.0358,\n",
       "          0.0384,  0.0371,  0.0408,  0.0383,  0.0375,  0.0373,  0.0376,  0.0361,\n",
       "          0.0359,  0.0386,  0.0372,  0.0389,  0.0392,  0.0353,  0.0366,  0.0359,\n",
       "          0.0383,  0.0435,  0.0356,  0.0366,  0.0359,  0.0358,  0.0357,  0.0391,\n",
       "          0.0388,  0.0358,  0.0355,  0.0360,  0.0355,  0.0429,  0.0367,  0.0364,\n",
       "          0.0358,  0.0425,  0.0440,  0.0367,  0.0389,  0.0448,  0.0397,  0.0444,\n",
       "          0.0369,  0.0390,  0.0518,  0.0369,  0.0371,  0.0360,  0.0401,  0.0392,\n",
       "          0.0356,  0.0369,  0.0370,  0.0401,  0.0359,  0.0381,  0.0375,  0.0374,\n",
       "          0.0379,  0.0446,  0.0353,  0.0359,  0.0359,  0.0366,  0.0369,  0.0427,\n",
       "          0.0359,  0.0354,  0.0437,  0.0364,  0.0423,  0.0447,  0.0357,  0.0363,\n",
       "          0.0402,  0.0374,  0.0389,  0.0370,  0.0370,  0.0458,  0.0364,  0.0454,\n",
       "          0.0357,  0.0366,  0.0368,  0.0368,  0.0391,  0.0404,  0.0370,  0.0388,\n",
       "          0.0374,  0.0439,  0.0411,  0.0458,  0.0354,  0.0384,  0.0468,  0.0353,\n",
       "          0.0422,  0.0364,  0.0405,  0.0417,  0.0418,  0.0388,  0.0397,  0.0369,\n",
       "          0.0409,  0.0356,  0.0385,  0.0384,  0.0428,  0.0465,  0.0384,  0.0402,\n",
       "          0.0423,  0.0374,  0.0379,  0.0376,  0.0357,  0.0369,  0.0375,  0.0374,\n",
       "          0.0356,  0.0379,  0.0431,  0.0465,  0.0414,  0.0355,  0.0383,  0.0372,\n",
       "          0.0393,  0.0370,  0.0358,  0.0379,  0.0356,  0.0404,  0.0485,  0.0369,\n",
       "          0.0372,  0.0396,  0.0353,  0.0362,  0.0387,  0.0369,  0.0423,  0.0367,\n",
       "          0.0369,  0.0388,  0.0357,  0.0555,  0.0355,  0.0369,  0.0362,  0.0384,\n",
       "          0.0440,  0.0375,  0.0360,  0.0373,  0.0357,  0.0357,  0.0368,  0.0391,\n",
       "          0.0380,  0.0376,  0.0353,  0.0424,  0.0475,  0.0380,  0.0393,  0.0377,\n",
       "          0.0404,  0.0434,  0.0369,  0.0358,  0.0384,  0.0355,  0.0355,  0.0359,\n",
       "          0.0451,  0.0362,  0.0364,  0.0407,  0.0365,  0.0373,  0.0397,  0.0391,\n",
       "          0.0389,  0.0372,  0.0386,  0.0381,  0.0359,  0.0374,  0.0418,  0.0513,\n",
       "          0.0361,  0.0356,  0.0366,  0.0386,  0.0385,  0.0411,  0.0463,  0.0354],\n",
       "        device='cuda:0'), gt_classes: tensor([ 2, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
       "         80, 80, 80, 80, 80, 80, 80, 80], device='cuda:0'), gt_boxes: Boxes(tensor([[202., 128., 647., 815.],\n",
       "         [202., 128., 647., 815.],\n",
       "         [202., 128., 647., 815.],\n",
       "         ...,\n",
       "         [202., 128., 647., 815.],\n",
       "         [202., 128., 647., 815.],\n",
       "         [202., 128., 647., 815.]], device='cuda:0'))])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposals_with_gt # label_and_sample_proposals output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p2', 'p3', 'p4', 'p5']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roi_heads.box_in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_outputs = []  # (predictor, predictions, proposals)\n",
    "prev_pred_boxes = None\n",
    "image_sizes = [x.image_size for x in proposals]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roi_heads.num_cascade_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import Boxes\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [test[f] for f in model.roi_heads.box_in_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _match_and_label_boxes(roi,proposals, stage, targets):\n",
    "    num_fg_samples, num_bg_samples = [], []\n",
    "    for proposals_per_image, targets_per_image in zip(proposals, targets):\n",
    "        match_quality_matrix = pairwise_iou(\n",
    "            targets_per_image.gt_boxes, proposals_per_image.proposal_boxes\n",
    "        )\n",
    "        # proposal_labels are 0 or 1\n",
    "        matched_idxs, proposal_labels = roi.proposal_matchers[stage](match_quality_matrix)\n",
    "        if len(targets_per_image) > 0:\n",
    "            gt_classes = targets_per_image.gt_classes[matched_idxs]\n",
    "            # Label unmatched proposals (0 label from matcher) as background (label=num_classes)\n",
    "            gt_classes[proposal_labels == 0] = roi.num_classes\n",
    "            gt_boxes = targets_per_image.gt_boxes[matched_idxs]\n",
    "        else:\n",
    "            gt_classes = torch.zeros_like(matched_idxs) + roi.num_classes\n",
    "            gt_boxes = Boxes(\n",
    "                targets_per_image.gt_boxes.tensor.new_zeros((len(proposals_per_image), 4))\n",
    "            )\n",
    "\n",
    "        proposals_per_image.gt_classes = gt_classes\n",
    "        proposals_per_image.gt_boxes = gt_boxes\n",
    "        # proposals_per_image.set(\"gt_classes\", gt_classes)\n",
    "        # proposals_per_image.set(\"gt_boxes\", gt_boxes)\n",
    "\n",
    "\n",
    "        num_fg_samples.append((proposal_labels == 1).sum().item())\n",
    "        num_bg_samples.append(proposal_labels.numel() - num_fg_samples[-1])\n",
    "\n",
    "\n",
    "    return proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1001, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposals[0].proposal_boxes.tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_features = model.roi_heads.box_pooler(features, [x.proposal_boxes for x in proposals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2002, 256, 7, 7])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(model.roi_heads.num_cascade_stages):\n",
    "    if k > 0:\n",
    "        # The output boxes of the previous stage are used to create the input\n",
    "        # proposals of the next stage.\n",
    "        proposals = model.roi_heads._create_proposals_from_boxes(prev_pred_boxes, image_sizes)\n",
    "        # if self.training:\n",
    "        # proposals = model.roi_heads._match_and_label_boxes(proposals, k, gt_instances)\n",
    "        proposals = _match_and_label_boxes(model.roi_heads,proposals, k, gt_instances)\n",
    "\n",
    "    predictions = model.roi_heads._run_stage(features, proposals, k)\n",
    "    prev_pred_boxes = model.roi_heads.box_predictor[k].predict_boxes(predictions, proposals)\n",
    "    head_outputs.append((model.roi_heads.box_predictor[k], predictions, proposals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roi_heads.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2002, 81])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([80, 80, 80,  ..., 80, 80,  5], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposals[0].gt_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposals[0].gt_classes\n",
    "# head_outputs[0][2][0].gt_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_outputs[0][2][0].gt_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = {}\n",
    "# for stage, (predictor, predictions, proposals) in enumerate(head_outputs):\n",
    "#     break\n",
    "    # predictor.losses(predictions, proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Instances(num_instances=1001, image_height=1024, image_width=1024, fields=[proposal_boxes: Boxes(tensor([[550.5065, 680.7580, 615.4693, 745.9525],\n",
       "         [935.3456, 232.8400, 967.8932, 263.9976],\n",
       "         [923.0463, 243.6731, 955.0397, 275.3087],\n",
       "         ...,\n",
       "         [883.5032, 284.6774, 915.4601, 316.4305],\n",
       "         [807.3915, 840.8939, 872.5300, 904.6993],\n",
       "         [157.7542, 292.7725, 751.0677, 768.8397]], device='cuda:0')), gt_classes: tensor([80, 80, 80,  ..., 80, 80,  5], device='cuda:0'), gt_boxes: Boxes(tensor([[156.8000, 290.3000, 751.1000, 770.3000],\n",
       "         [156.8000, 290.3000, 751.1000, 770.3000],\n",
       "         [156.8000, 290.3000, 751.1000, 770.3000],\n",
       "         ...,\n",
       "         [156.8000, 290.3000, 751.1000, 770.3000],\n",
       "         [156.8000, 290.3000, 751.1000, 770.3000],\n",
       "         [156.8000, 290.3000, 751.1000, 770.3000]], device='cuda:0'))]),\n",
       " Instances(num_instances=1001, image_height=1024, image_width=1024, fields=[proposal_boxes: Boxes(tensor([[ 116.7133,  501.1270,  161.3514,  523.2927],\n",
       "         [ 727.4805, 1000.6904,  760.2451, 1023.9724],\n",
       "         [ 919.3171,  824.5770,  951.7679,  856.5165],\n",
       "         ...,\n",
       "         [ 975.1061,  404.0626, 1007.6722,  436.5891],\n",
       "         [ 479.5686,  948.0272,  512.2701,  980.0901],\n",
       "         [ 201.9757,  131.6670,  646.5234,  811.8500]], device='cuda:0')), gt_classes: tensor([80, 80, 80,  ..., 80, 80,  2], device='cuda:0'), gt_boxes: Boxes(tensor([[202., 128., 647., 815.],\n",
       "         [202., 128., 647., 815.],\n",
       "         [202., 128., 647., 815.],\n",
       "         ...,\n",
       "         [202., 128., 647., 815.],\n",
       "         [202., 128., 647., 815.],\n",
       "         [202., 128., 647., 815.]], device='cuda:0'))])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, proposal_deltas = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2002, 81])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2002, 4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_deltas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.layers import cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([80, 80, 80,  ..., 80, 80,  5], device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposals[0].gt_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_classes = (\n",
    "    cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([80, 80, 80,  ..., 80, 80,  2], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2002, 4])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxes = cat(\n",
    "    [(p.gt_boxes if p.has(\"gt_boxes\") else p.proposal_boxes).tensor for p in proposals],\n",
    "    dim=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roi_heads.box_predictor[k].box_reg_loss(\n",
    "                proposal_boxes, gt_boxes, proposal_deltas, gt_classes\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.layers import nonzero_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dim = proposal_boxes.shape[1]  # 4 or 5\n",
    "# Regression loss is only computed for foreground proposals (those matched to a GT)\n",
    "fg_inds = nonzero_tuple((gt_classes >= 0) & (gt_classes < 10))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposal_deltas.shape[1] == box_dim\n",
    "fg_pred_deltas = proposal_deltas[fg_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fg_pred_deltas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.4823e-05,  5.7946e-03, -4.0293e-04, -1.4985e-02],\n",
       "        [ 7.0027e-03,  7.1271e-04, -1.4262e-03, -1.2130e-02]], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_pred_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 7, 7])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_features[fg_inds].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_boxes[fg_inds].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.roi_heads.box_predictor[k].box2box_transform.apply_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isinstance(anchors[0], Boxes)\n",
    "anchors = type(anchors[0]).cat(anchors).tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_pred_deltas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat([proposal_boxes[fg_inds]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat([fg_pred_deltas.unsqueeze(0)], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_boxes = [\n",
    "    model.roi_heads.box_predictor[1].box2box_transform.apply_deltas(k, cat([proposal_boxes[fg_inds]])) for k in cat([fg_pred_deltas.unsqueeze(0)], dim=1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[157.7645, 293.2669, 751.0542, 768.6212],\n",
       "         [202.1630, 132.1035, 646.6474, 811.4620]], device='cuda:0',\n",
       "        grad_fn=<ReshapeAliasBackward0>)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_boxes = [\n",
    "#     model.roi_heads.box_predictor[1].box2box_transform.apply_deltas(k, proposal_boxes[fg_inds]) for k in cat([fg_pred_deltas.unsqueeze(0)], dim=1)\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.layers import ciou_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000, 2001], device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.stack(pred_boxes)[fg_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_box_reg = ciou_loss(\n",
    "#     torch.stack(pred_boxes)[fg_inds], torch.stack(gt_boxes)[fg_inds], reduction=\"sum\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.4823e-05,  5.7946e-03, -4.0293e-04, -1.4985e-02],\n",
       "        [ 7.0027e-03,  7.1271e-04, -1.4262e-03, -1.2130e-02]], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_pred_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[156.8000, 290.3000, 751.1000, 770.3000],\n",
       "        [202.0000, 128.0000, 647.0000, 815.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_boxes[fg_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_box = model.roi_heads.box_predictor[1].box2box_transform.apply_deltas(fg_pred_deltas, anchors[fg_inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[157.7645, 293.2669, 751.0542, 768.6212],\n",
       "         [202.1630, 132.1035, 646.6474, 811.4620]], device='cuda:0',\n",
       "        grad_fn=<ReshapeAliasBackward0>)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_box_reg = ciou_loss(\n",
    "    torch.stack(pred_boxes), torch.stack([gt_boxes[fg_inds]]), reduction=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_box_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1000, 2001], device='cuda:0'),)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_tuple((gt_classes >= 0) & (gt_classes < 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], device='cuda:0', dtype=torch.int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_tuple((loss_box_reg.squeeze() < 0.009))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_id = nonzero_tuple((loss_box_reg.squeeze() < 0.009))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False], device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_classes==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasive_id = nonzero_tuple((gt_classes ==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_u = nonzero_tuple((gt_classes >= 0) & (gt_classes<10))[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 7, 7])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_s = nonzero_tuple((loss_box_reg.squeeze() < 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5407,  0.8819,  0.4522,  ...,  0.5720,  0.6507,  0.0340],\n",
       "          [ 0.5867,  0.3559,  0.1641,  ...,  0.1332,  0.0601, -0.3083],\n",
       "          [ 0.3466,  0.3771,  0.2040,  ..., -0.1141, -0.4555, -0.5321],\n",
       "          ...,\n",
       "          [ 0.2350,  0.1901,  0.0882,  ..., -0.4161,  0.3196,  0.2546],\n",
       "          [-0.2128,  0.1694,  0.2794,  ...,  0.3189,  0.0500,  0.1908],\n",
       "          [-0.7755, -1.0153, -0.1351,  ...,  0.4753,  0.2535,  0.3023]],\n",
       "\n",
       "         [[-1.0128, -0.6656, -0.6350,  ..., -0.0180,  0.0254, -0.4425],\n",
       "          [-0.7938, -0.5283, -0.4104,  ...,  0.2164,  0.3022, -0.4729],\n",
       "          [-0.5916, -0.4589,  0.0668,  ..., -0.0486, -0.1997, -0.2909],\n",
       "          ...,\n",
       "          [-0.4070,  0.0803,  0.0857,  ..., -0.7427, -0.5327, -0.2231],\n",
       "          [-0.3752, -0.3980, -0.4383,  ..., -0.3977, -0.4066, -0.1119],\n",
       "          [-0.4523, -0.4313, -0.1702,  ..., -0.1062, -0.1871, -0.1714]],\n",
       "\n",
       "         [[ 0.3573,  0.4307,  0.1601,  ...,  0.0308,  0.0963,  0.2902],\n",
       "          [ 0.3264,  0.1387,  0.0324,  ..., -0.0130,  0.0136,  0.4555],\n",
       "          [ 0.2977,  0.2241,  0.1508,  ..., -0.0712, -0.0152,  0.0607],\n",
       "          ...,\n",
       "          [ 0.2172,  0.0967, -0.0165,  ...,  0.1989,  0.4563,  0.3132],\n",
       "          [-0.0288, -0.0335,  0.1073,  ...,  0.1690,  0.1181, -0.0429],\n",
       "          [ 0.5354,  0.1901,  0.2414,  ..., -0.0059, -0.1604, -0.0143]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0942, -0.2524,  0.0366,  ..., -0.0482, -0.1379, -0.0728],\n",
       "          [-0.3177,  0.0873,  0.3758,  ...,  0.1190,  0.0394, -0.3224],\n",
       "          [-0.0386,  0.1747,  0.0472,  ...,  0.1100, -0.0211, -0.3558],\n",
       "          ...,\n",
       "          [ 0.0668, -0.0508, -0.0051,  ..., -0.5945, -0.8118, -0.9876],\n",
       "          [ 0.4168,  0.1554,  0.1738,  ..., -0.9820, -0.9768, -1.2137],\n",
       "          [ 0.1751, -0.3733, -0.6813,  ..., -1.4015, -1.0867, -1.1538]],\n",
       "\n",
       "         [[-1.5522, -1.9144, -1.8271,  ..., -1.3714, -1.4196, -1.5164],\n",
       "          [-1.7138, -1.6801, -1.5052,  ..., -1.1134, -1.1911, -1.3255],\n",
       "          [-1.3214, -1.4378, -1.3703,  ..., -1.1072, -1.1904, -0.9548],\n",
       "          ...,\n",
       "          [-1.3831, -1.0895, -0.9779,  ..., -1.3009, -1.4098, -1.1623],\n",
       "          [-1.2539, -0.9001, -0.9646,  ..., -1.2609, -1.3367, -0.9973],\n",
       "          [-1.5629, -0.9402, -0.2726,  ..., -0.7099, -0.7211, -0.7742]],\n",
       "\n",
       "         [[ 0.0654,  0.1592,  0.0319,  ..., -0.4622, -0.3452, -0.3692],\n",
       "          [ 0.1608, -0.0650, -0.4478,  ..., -0.3441, -0.4228, -0.6046],\n",
       "          [-0.2319, -0.5347, -0.6708,  ..., -0.4478, -0.4335, -0.4931],\n",
       "          ...,\n",
       "          [-0.4615, -0.4722, -0.3378,  ..., -0.1949,  0.4253,  0.6504],\n",
       "          [-0.2118, -0.5652, -0.7573,  ...,  0.1585,  0.3060,  0.6447],\n",
       "          [-0.2648, -0.4076, -0.2652,  ...,  0.9678,  0.9787,  0.9274]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5219, -0.1080, -0.1770,  ..., -0.0036, -0.1753,  0.0453],\n",
       "          [ 0.8322, -0.1514, -0.5190,  ..., -0.3170,  0.1717,  0.2893],\n",
       "          [ 0.7496,  0.1100, -0.4461,  ...,  0.1476,  0.4149,  0.0258],\n",
       "          ...,\n",
       "          [ 0.2268,  0.1533, -0.4801,  ..., -0.0614,  0.0683,  0.5002],\n",
       "          [-0.0950,  0.0696, -0.2328,  ..., -0.0945,  0.0694,  0.6787],\n",
       "          [ 0.4132, -0.6001, -0.2499,  ...,  0.2965,  0.0678,  0.4213]],\n",
       "\n",
       "         [[-0.4380, -0.4532, -0.1994,  ..., -0.0311, -0.0599, -0.1118],\n",
       "          [-0.3639, -0.2882, -0.0430,  ..., -0.2673, -0.2883, -0.2488],\n",
       "          [-0.5579, -0.6101, -0.1040,  ..., -0.6055, -0.5363, -0.4065],\n",
       "          ...,\n",
       "          [-0.3007, -0.9662, -0.3320,  ..., -0.0187, -0.7106, -0.7107],\n",
       "          [-0.4348, -0.4258, -0.2869,  ..., -0.1432, -0.3973, -0.6664],\n",
       "          [-0.7718, -0.4960, -0.2738,  ..., -0.3608, -0.4352, -0.2773]],\n",
       "\n",
       "         [[-0.3524, -0.0640, -0.0275,  ..., -0.2753, -0.2547, -0.3010],\n",
       "          [-0.4499,  0.1637, -0.3144,  ...,  0.1102,  0.0787, -0.2661],\n",
       "          [-0.4274,  0.2730, -0.3570,  ...,  0.1965,  0.3645, -0.1177],\n",
       "          ...,\n",
       "          [-0.7276,  0.1835,  0.1207,  ...,  0.4508,  0.2380,  0.3343],\n",
       "          [-0.3398, -0.2782,  0.2866,  ...,  0.2963,  0.4936,  0.4292],\n",
       "          [ 0.2492,  0.3688,  0.5301,  ...,  0.3059,  0.1645,  0.1556]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.5704, -0.8595, -0.6243,  ..., -0.5052, -0.5230, -0.5419],\n",
       "          [-0.7493, -0.5823, -0.7544,  ..., -0.7771, -0.5821, -0.7700],\n",
       "          [-1.5801, -0.6242, -0.7347,  ..., -1.2226, -0.5627, -1.0847],\n",
       "          ...,\n",
       "          [-1.4242, -1.0326, -0.7677,  ..., -1.2335, -0.9709, -1.2123],\n",
       "          [-1.2267, -0.9793, -0.5082,  ..., -0.8063, -0.7384, -0.9453],\n",
       "          [-0.9735, -1.0253, -0.5404,  ..., -0.9750, -0.6714, -0.7108]],\n",
       "\n",
       "         [[-1.6283, -1.7381, -1.4950,  ..., -1.2880, -1.2539, -1.6246],\n",
       "          [-0.9341, -1.1464, -1.1993,  ..., -1.0719, -0.9441, -1.4551],\n",
       "          [-1.4371, -1.1047, -1.2171,  ..., -1.4718, -1.2562, -1.6019],\n",
       "          ...,\n",
       "          [-2.3579, -1.3634, -1.3416,  ..., -1.4346, -1.1797, -1.5690],\n",
       "          [-2.2123, -1.5640, -1.1931,  ..., -1.2874, -1.2240, -1.6054],\n",
       "          [-1.8133, -1.9350, -1.3823,  ..., -1.3595, -1.0808, -1.2305]],\n",
       "\n",
       "         [[ 0.2414, -0.2064, -0.4267,  ..., -0.4142, -0.1033,  0.3689],\n",
       "          [-0.4491, -0.9275, -0.8911,  ..., -0.4891, -0.4942,  0.0024],\n",
       "          [ 0.3601, -0.7809, -0.8749,  ...,  0.1228, -0.4314, -0.0033],\n",
       "          ...,\n",
       "          [ 0.0693, -1.0049, -0.9356,  ..., -0.0836,  0.2050,  0.2734],\n",
       "          [-0.1229, -0.9458, -1.0464,  ..., -0.1174,  0.4888,  0.4041],\n",
       "          [-0.2220, -0.3712, -0.9928,  ...,  0.1426,  0.1554,  0.3295]]]],\n",
       "       device='cuda:0', grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_features[class_u][iou_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], device='cuda:0', dtype=torch.int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrast_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_features[contrasive_id][contrast_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrasive_id = nonzero_tuple((gt_classes ==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fin = box_features[contrasive_id][contrast_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfin\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fin' is not defined"
     ]
    }
   ],
   "source": [
    "fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 256, 7, 7])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# box_features[fg_inds].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
